# Overview

## Motivation
> Modern 3D vision advancements rely on data driven methods and thus, task specific annotated datasets.
> Especially for geometric inference tasks like depth and surface estimation, the collection of high quality data is very challenging, expensive and laborious.
> While considerable efforts have been made for traditional pinhole cameras, the same cannot be said for omnidirectional ones.
> Our __3D60<sup>o</sup>__ dataset fills a very important gap in data-driven spherical 3D vision and namely for monocular and stereo dense depth and surface estimation.
> _We originate by exploiting the efforts made in providing synthetic and real scanned 3D datasets of interior spaces and re-using them via ray-tracing in order to generate high quality, densely annotated spherical panoramas._

<!-- However, collecting high quality depth measurements aligned with tradtional camera input is a challenging, laborious and expensive process. -->
<!-- This has led to the utilization of self-supervised methods for learning to infer depth from monocular images. -->
<!-- Nonetheless, fully supervised approaches are unquestionnably more efficient and preferable. -->

<!--
# Motivation
* data-drive 3d vision
* lack of densely data
* self-supervised or unsupervised
-->
<!--
## Omnidirectional 3D Vision
* even harder to collect data (sensors, cost, no-depth)
* tough to collect stereo data
* only video for self- or unsupervised
-->
<!--
## 3D Scenes
* however we have 3D datasets
* buildings/scans/indoors
* real/synthetic
-->
<!--
## Concept
* re-use the 3D dataset efforts
* synthesize 360 data
* ray-casting
* color, depth, normals, stereo
-->

## Description


## Showcase


# Usage

## Download


## Organization


## Tools

# Bibliography

## Citations


## References


